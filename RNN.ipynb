{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled35.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCV30xyVhFbE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqqYdOm-mTRp"
      },
      "source": [
        "dataset= pd.read_csv('coughdf.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NHLOLChsIwx"
      },
      "source": [
        "updt=dataset.drop('expert_labels_3', inplace=True, axis=1)\n",
        "updt=dataset.drop('expert_labels_2', inplace=True, axis=1)\n",
        "updt=dataset.drop('expert_labels_1', inplace=True, axis=1)\n",
        "updt=dataset.drop('datetime', inplace=True, axis=1)\n",
        "updt=dataset.dropna(subset=['status'])\n",
        "updt=dataset.dropna(subset=['gender','respiratory_condition','fever_muscle_pain'],how='all')\n",
        "updt=updt.replace(to_replace =[\"other\"], \n",
        "                            value =\"female\")\n",
        "updt=updt.replace(to_replace =[\"symptomatic\"], \n",
        "                            value =\"COVID-19\")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MauBL9BVVm_o"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "levelencoder= preprocessing.LabelEncoder()\n",
        "updt['fever_muscle_pain']= levelencoder.fit_transform(updt['fever_muscle_pain'])\n",
        "updt['gender']= levelencoder.fit_transform(updt['gender'])\n",
        "updt['respiratory_condition']= levelencoder.fit_transform(updt['respiratory_condition'])\n",
        "updt['status']= levelencoder.fit_transform(updt['status'])\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "bcP5AVK3c2pi",
        "outputId": "ef6f99cd-5dfc-48bc-db38-bba21d78b311"
      },
      "source": [
        "updt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>cough_detected</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>respiratory_condition</th>\n",
              "      <th>fever_muscle_pain</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.9609</td>\n",
              "      <td>31.3</td>\n",
              "      <td>34.8</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.9609</td>\n",
              "      <td>31.3</td>\n",
              "      <td>34.8</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.9301</td>\n",
              "      <td>40.0</td>\n",
              "      <td>-75.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0306</td>\n",
              "      <td>13.8</td>\n",
              "      <td>-89.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19983</th>\n",
              "      <td>19983</td>\n",
              "      <td>0.9820</td>\n",
              "      <td>19.0</td>\n",
              "      <td>72.8</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19985</th>\n",
              "      <td>19985</td>\n",
              "      <td>0.6354</td>\n",
              "      <td>41.0</td>\n",
              "      <td>28.7</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19986</th>\n",
              "      <td>19986</td>\n",
              "      <td>0.9866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19989</th>\n",
              "      <td>19989</td>\n",
              "      <td>0.5634</td>\n",
              "      <td>41.9</td>\n",
              "      <td>60.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19990</th>\n",
              "      <td>19990</td>\n",
              "      <td>0.9954</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11259 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  cough_detected  ...  fever_muscle_pain  status\n",
              "0               0          0.9609  ...                  0       1\n",
              "1               1          0.9609  ...                  0       1\n",
              "2               2          0.9301  ...                  0       1\n",
              "4               4          0.9968  ...                  0       1\n",
              "6               6          0.0306  ...                  1       0\n",
              "...           ...             ...  ...                ...     ...\n",
              "19983       19983          0.9820  ...                  0       1\n",
              "19985       19985          0.6354  ...                  0       1\n",
              "19986       19986          0.9866  ...                  0       1\n",
              "19989       19989          0.5634  ...                  1       0\n",
              "19990       19990          0.9954  ...                  0       1\n",
              "\n",
              "[11259 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQe4-UP3j7Cs"
      },
      "source": [
        "training CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG-xrh5a8M05"
      },
      "source": [
        "m = updt.iloc[:, 1:].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0ojw4RA8eJS",
        "outputId": "83d6e397-c85f-4cb6-bf6b-3186af14eb3d"
      },
      "source": [
        "m.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11259, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvFClk-NXvB3"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(m[:, 1:4])\n",
        "m[:, 1:4] = imputer.transform(m[:, 1:4])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx3uGUVL8kTY"
      },
      "source": [
        "def split_sequences(sequences, n_steps):\n",
        "\ta, b = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "    \n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\ta.append(seq_x)\n",
        "\t\tb.append(seq_y)\n",
        "\treturn array(a), array(b)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi7HiQntWJEe"
      },
      "source": [
        "from numpy import array\n",
        "a, b = split_sequences(m, 8)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCEgf-WVxJ2D",
        "outputId": "5c1e6e4a-7e91-4bf2-8781-94d296e8520d"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11252, 8, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XNSkAYCXAFc",
        "outputId": "e81426ed-8cc2-47aa-fb74-32385910040d"
      },
      "source": [
        "b"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAfH0sYCcj1t"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "a_train, a_test, b_train, b_test = train_test_split(a, b, test_size = 0.2, random_state = 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvt8iu3IZj8d"
      },
      "source": [
        "n_features = a.shape[2]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9y0SOTIZnsK",
        "outputId": "0dba4a85-62b9-43ae-b972-fc527daec0a8"
      },
      "source": [
        "n_features"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBF_DEgvZ7Vf"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout, LSTM\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "665DlxZhZ0ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f06a049-11e0-4a2e-be82-d0d5cbcaff0c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, activation='relu', input_shape=(a_train.shape[1:]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3, decay =  1e-5)\n",
        "model.compile(loss= 'mse' ,optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#model.compile(optimizer='adam', loss='sparse_categorical_cr',metrics = ['accuracy'])\n",
        "# fit model\n",
        "model.fit(a_train,  b_train,  epochs=1000, validation_data=(a_test,b_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "282/282 [==============================] - 10s 26ms/step - loss: 0.2278 - accuracy: 0.7500 - val_loss: 0.1868 - val_accuracy: 0.7530\n",
            "Epoch 2/1000\n",
            "282/282 [==============================] - 7s 24ms/step - loss: 0.1848 - accuracy: 0.7575 - val_loss: 0.1820 - val_accuracy: 0.7526\n",
            "Epoch 3/1000\n",
            "282/282 [==============================] - 7s 24ms/step - loss: 0.1806 - accuracy: 0.7570 - val_loss: 0.1845 - val_accuracy: 0.7526\n",
            "Epoch 4/1000\n",
            "282/282 [==============================] - 7s 24ms/step - loss: 0.1784 - accuracy: 0.7572 - val_loss: 0.1774 - val_accuracy: 0.7521\n",
            "Epoch 5/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1765 - accuracy: 0.7572 - val_loss: 0.1797 - val_accuracy: 0.7526\n",
            "Epoch 6/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1728 - accuracy: 0.7575 - val_loss: 0.1746 - val_accuracy: 0.7526\n",
            "Epoch 7/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1707 - accuracy: 0.7600 - val_loss: 0.1740 - val_accuracy: 0.7512\n",
            "Epoch 8/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1689 - accuracy: 0.7589 - val_loss: 0.1740 - val_accuracy: 0.7534\n",
            "Epoch 9/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1683 - accuracy: 0.7597 - val_loss: 0.1770 - val_accuracy: 0.7517\n",
            "Epoch 10/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1647 - accuracy: 0.7662 - val_loss: 0.1746 - val_accuracy: 0.7543\n",
            "Epoch 11/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1633 - accuracy: 0.7668 - val_loss: 0.1762 - val_accuracy: 0.7486\n",
            "Epoch 12/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1596 - accuracy: 0.7721 - val_loss: 0.1801 - val_accuracy: 0.7432\n",
            "Epoch 13/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1577 - accuracy: 0.7742 - val_loss: 0.1826 - val_accuracy: 0.7472\n",
            "Epoch 14/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1548 - accuracy: 0.7808 - val_loss: 0.1790 - val_accuracy: 0.7446\n",
            "Epoch 15/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1506 - accuracy: 0.7889 - val_loss: 0.1842 - val_accuracy: 0.7375\n",
            "Epoch 16/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1465 - accuracy: 0.7949 - val_loss: 0.1892 - val_accuracy: 0.7330\n",
            "Epoch 17/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1475 - accuracy: 0.7911 - val_loss: 0.1858 - val_accuracy: 0.7352\n",
            "Epoch 18/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1421 - accuracy: 0.8028 - val_loss: 0.1901 - val_accuracy: 0.7472\n",
            "Epoch 19/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1362 - accuracy: 0.8116 - val_loss: 0.1860 - val_accuracy: 0.7379\n",
            "Epoch 20/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1314 - accuracy: 0.8167 - val_loss: 0.1920 - val_accuracy: 0.7361\n",
            "Epoch 21/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1282 - accuracy: 0.8221 - val_loss: 0.1934 - val_accuracy: 0.7335\n",
            "Epoch 22/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1254 - accuracy: 0.8281 - val_loss: 0.2026 - val_accuracy: 0.7312\n",
            "Epoch 23/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1192 - accuracy: 0.8346 - val_loss: 0.1962 - val_accuracy: 0.7414\n",
            "Epoch 24/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1134 - accuracy: 0.8438 - val_loss: 0.2011 - val_accuracy: 0.7330\n",
            "Epoch 25/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1095 - accuracy: 0.8512 - val_loss: 0.2009 - val_accuracy: 0.7383\n",
            "Epoch 26/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1105 - accuracy: 0.8491 - val_loss: 0.2042 - val_accuracy: 0.7326\n",
            "Epoch 27/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1051 - accuracy: 0.8573 - val_loss: 0.2150 - val_accuracy: 0.7308\n",
            "Epoch 28/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1032 - accuracy: 0.8580 - val_loss: 0.2095 - val_accuracy: 0.7268\n",
            "Epoch 29/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0977 - accuracy: 0.8656 - val_loss: 0.2105 - val_accuracy: 0.7352\n",
            "Epoch 30/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0949 - accuracy: 0.8716 - val_loss: 0.2169 - val_accuracy: 0.7317\n",
            "Epoch 31/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0977 - accuracy: 0.8655 - val_loss: 0.2221 - val_accuracy: 0.7157\n",
            "Epoch 32/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0932 - accuracy: 0.8745 - val_loss: 0.2196 - val_accuracy: 0.7263\n",
            "Epoch 33/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0891 - accuracy: 0.8797 - val_loss: 0.2147 - val_accuracy: 0.7250\n",
            "Epoch 34/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0845 - accuracy: 0.8837 - val_loss: 0.2232 - val_accuracy: 0.7277\n",
            "Epoch 35/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0834 - accuracy: 0.8872 - val_loss: 0.2224 - val_accuracy: 0.7246\n",
            "Epoch 36/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0793 - accuracy: 0.8969 - val_loss: 0.2349 - val_accuracy: 0.7041\n",
            "Epoch 37/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0771 - accuracy: 0.8979 - val_loss: 0.2260 - val_accuracy: 0.7241\n",
            "Epoch 38/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0795 - accuracy: 0.8943 - val_loss: 0.2300 - val_accuracy: 0.7135\n",
            "Epoch 39/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0726 - accuracy: 0.9006 - val_loss: 0.2348 - val_accuracy: 0.7143\n",
            "Epoch 40/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0688 - accuracy: 0.9087 - val_loss: 0.2389 - val_accuracy: 0.7068\n",
            "Epoch 41/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0713 - accuracy: 0.9069 - val_loss: 0.2461 - val_accuracy: 0.7077\n",
            "Epoch 42/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0731 - accuracy: 0.9050 - val_loss: 0.2432 - val_accuracy: 0.7077\n",
            "Epoch 43/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0642 - accuracy: 0.9162 - val_loss: 0.2356 - val_accuracy: 0.7210\n",
            "Epoch 44/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0660 - accuracy: 0.9139 - val_loss: 0.2421 - val_accuracy: 0.7086\n",
            "Epoch 45/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0656 - accuracy: 0.9153 - val_loss: 0.2415 - val_accuracy: 0.7121\n",
            "Epoch 46/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0604 - accuracy: 0.9221 - val_loss: 0.2382 - val_accuracy: 0.7210\n",
            "Epoch 47/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0621 - accuracy: 0.9191 - val_loss: 0.2347 - val_accuracy: 0.7219\n",
            "Epoch 48/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0592 - accuracy: 0.9231 - val_loss: 0.2394 - val_accuracy: 0.7201\n",
            "Epoch 49/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0622 - accuracy: 0.9185 - val_loss: 0.2365 - val_accuracy: 0.7188\n",
            "Epoch 50/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0553 - accuracy: 0.9268 - val_loss: 0.2522 - val_accuracy: 0.7055\n",
            "Epoch 51/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0565 - accuracy: 0.9283 - val_loss: 0.2493 - val_accuracy: 0.7010\n",
            "Epoch 52/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0596 - accuracy: 0.9225 - val_loss: 0.2550 - val_accuracy: 0.6930\n",
            "Epoch 53/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0575 - accuracy: 0.9250 - val_loss: 0.2458 - val_accuracy: 0.7077\n",
            "Epoch 54/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0550 - accuracy: 0.9285 - val_loss: 0.2474 - val_accuracy: 0.7068\n",
            "Epoch 55/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0529 - accuracy: 0.9318 - val_loss: 0.2487 - val_accuracy: 0.7108\n",
            "Epoch 56/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0540 - accuracy: 0.9318 - val_loss: 0.2598 - val_accuracy: 0.6926\n",
            "Epoch 57/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0508 - accuracy: 0.9347 - val_loss: 0.2596 - val_accuracy: 0.6921\n",
            "Epoch 58/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0496 - accuracy: 0.9370 - val_loss: 0.2568 - val_accuracy: 0.7024\n",
            "Epoch 59/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0503 - accuracy: 0.9353 - val_loss: 0.2498 - val_accuracy: 0.7095\n",
            "Epoch 60/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0491 - accuracy: 0.9386 - val_loss: 0.2571 - val_accuracy: 0.7041\n",
            "Epoch 61/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0495 - accuracy: 0.9371 - val_loss: 0.2519 - val_accuracy: 0.7032\n",
            "Epoch 62/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0440 - accuracy: 0.9440 - val_loss: 0.2525 - val_accuracy: 0.7086\n",
            "Epoch 63/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0417 - accuracy: 0.9488 - val_loss: 0.2613 - val_accuracy: 0.6948\n",
            "Epoch 64/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0436 - accuracy: 0.9440 - val_loss: 0.2581 - val_accuracy: 0.6988\n",
            "Epoch 65/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0416 - accuracy: 0.9471 - val_loss: 0.2533 - val_accuracy: 0.7015\n",
            "Epoch 66/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0416 - accuracy: 0.9461 - val_loss: 0.2515 - val_accuracy: 0.7086\n",
            "Epoch 67/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0450 - accuracy: 0.9436 - val_loss: 0.2599 - val_accuracy: 0.6984\n",
            "Epoch 68/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0423 - accuracy: 0.9463 - val_loss: 0.2571 - val_accuracy: 0.7028\n",
            "Epoch 69/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0425 - accuracy: 0.9451 - val_loss: 0.2499 - val_accuracy: 0.7072\n",
            "Epoch 70/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0427 - accuracy: 0.9451 - val_loss: 0.2538 - val_accuracy: 0.7059\n",
            "Epoch 71/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0394 - accuracy: 0.9490 - val_loss: 0.2613 - val_accuracy: 0.6984\n",
            "Epoch 72/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0367 - accuracy: 0.9529 - val_loss: 0.2546 - val_accuracy: 0.7077\n",
            "Epoch 73/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0363 - accuracy: 0.9539 - val_loss: 0.2643 - val_accuracy: 0.6988\n",
            "Epoch 74/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0405 - accuracy: 0.9468 - val_loss: 0.2518 - val_accuracy: 0.7059\n",
            "Epoch 75/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0362 - accuracy: 0.9538 - val_loss: 0.2647 - val_accuracy: 0.7010\n",
            "Epoch 76/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0448 - accuracy: 0.9402 - val_loss: 0.2572 - val_accuracy: 0.6979\n",
            "Epoch 77/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0402 - accuracy: 0.9489 - val_loss: 0.2560 - val_accuracy: 0.7041\n",
            "Epoch 78/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0330 - accuracy: 0.9591 - val_loss: 0.2653 - val_accuracy: 0.6935\n",
            "Epoch 79/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0364 - accuracy: 0.9541 - val_loss: 0.2528 - val_accuracy: 0.7121\n",
            "Epoch 80/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0350 - accuracy: 0.9563 - val_loss: 0.2521 - val_accuracy: 0.7170\n",
            "Epoch 81/1000\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.0380 - accuracy: 0.9527 - val_loss: 0.2543 - val_accuracy: 0.7095\n",
            "Epoch 82/1000\n",
            "282/282 [==============================] - 7s 26ms/step - loss: 0.0353 - accuracy: 0.9568 - val_loss: 0.2633 - val_accuracy: 0.7064\n",
            "Epoch 83/1000\n",
            "280/282 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9550"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZZIyVYvUdNG"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(a_test,b_test)\n",
        "print('test_acc: ',test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfW4m9I3PwCy"
      },
      "source": [
        ""
      ]
    }
  ]
}